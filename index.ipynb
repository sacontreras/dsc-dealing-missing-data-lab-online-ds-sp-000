{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Data - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll work through strategies for data cleaning and dealing with null values (NaNs).\n",
    "\n",
    "## Objectives\n",
    "* Detect missing data in Pandas using .describe(), .info(), .isnull and .notnull\n",
    "* Replace/drop missing data in Pandas using .fillna and .dropna\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "In this lab, we'll continue working with the _Titanic Survivors_ dataset, which can be found in `titanic.csv`.\n",
    "\n",
    "Before we can get going, we'll need to import the usual libraries.  In the cell below, import:\n",
    "* `pandas` as `pd`\n",
    "* `numpy` as `np`\n",
    "* `matplotlib.pyplot` as `plt`\n",
    "* set `%matplotlib inline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries below\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get started by reading in the data from the **titanic.csv** file and storing it in a DataFrame in the `df` variable below. Subsequently, be sure to preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived Pclass  \\\n",
       "0           0            1         0      3   \n",
       "1           1            2         1      1   \n",
       "2           2            3         1      3   \n",
       "3           3            4         1      1   \n",
       "4           4            5         0      3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Null Values in a DataFrame\n",
    "\n",
    "Before we can deal with null values, we first need to find them. There are several easy ways to detect them.  We will start by answering very general questions, such as \"does this DataFrame contain any null values?\", and then narrowing our focus each time the answer to a question is \"yes\".\n",
    "\n",
    "We'll start by checking to see if the DataFrame contains **any** null values (NaNs) at all. \n",
    "\n",
    "**_Hint_**: If you do this correctly, it will require method chaining, and will return a boolean value for each column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  \\\n",
       "0         False        False     False   False  False  False  False  False   \n",
       "1         False        False     False   False  False  False  False  False   \n",
       "2         False        False     False   False  False  False  False  False   \n",
       "3         False        False     False   False  False  False  False  False   \n",
       "4         False        False     False   False  False  False  False  False   \n",
       "..          ...          ...       ...     ...    ...    ...    ...    ...   \n",
       "886       False        False     False   False  False  False  False  False   \n",
       "887       False        False     False   False  False  False  False  False   \n",
       "888       False        False     False   False  False  False   True  False   \n",
       "889       False        False     False   False  False  False  False  False   \n",
       "890       False        False     False   False  False  False  False  False   \n",
       "\n",
       "     Parch  Ticket   Fare  Cabin  Embarked  \n",
       "0    False   False  False   True     False  \n",
       "1    False   False  False  False     False  \n",
       "2    False   False  False   True     False  \n",
       "3    False   False  False  False     False  \n",
       "4    False   False  False   True     False  \n",
       "..     ...     ...    ...    ...       ...  \n",
       "886  False   False  False   True     False  \n",
       "887  False   False  False  False     False  \n",
       "888  False   False  False   True     False  \n",
       "889  False   False  False  False     False  \n",
       "890  False   False  False   True     False  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know which columns contain null values, but not how many. \n",
    "\n",
    "In the cell below, check chain a different method with `isna()` to check how many total null values are in each column.  \n",
    "\n",
    "Expected Output:\n",
    "\n",
    "```\n",
    "PassengerId      0\n",
    "Survived         0\n",
    "Pclass           0\n",
    "Name             0\n",
    "Sex              0\n",
    "Age            177\n",
    "SibSp            0\n",
    "Parch            0\n",
    "Ticket           0\n",
    "Fare             0\n",
    "Cabin          687\n",
    "Embarked         2\n",
    "dtype: int64```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how many null values exist in each column, we can make some decisions about how to deal with them.  \n",
    "\n",
    "We'll deal with each column individually, and employ a different strategy for each.  \n",
    "\n",
    "\n",
    "### Dropping the Column\n",
    "\n",
    "The first column we'll deal with is the `Cabin` column.  We'll begin by examining this column more closely. \n",
    "\n",
    "\n",
    "In the cell below:\n",
    "* Determine what percentage of rows in this column contain missing values\n",
    "* Print out the number of unique values in this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Cabin' contains 687 missing values out of 891 total (77.1%).\n",
      "Column 'Cabin' contains the following unique values:\n",
      "[nan 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'B78' 'D33'\n",
      " 'B30' 'C52' 'B28' 'C83' 'F33' 'F G73' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
      " 'B58 B60' 'E101' 'F E69' 'D47' 'B86' 'F2' 'C2' 'E33' 'B19' 'A7' 'C49'\n",
      " 'F4' 'A32' 'B4' 'B80' 'A31' 'D36' 'D15' 'C93' 'C78' 'D35' 'C87' 'B77'\n",
      " 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'A19' 'B49' 'D' 'C22 C26' 'C106'\n",
      " 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'B18' 'C124' 'C91'\n",
      " 'E40' 'T' 'C128' 'D37' 'B35' 'E50' 'C82' 'B96 B98' 'E10' 'E44' 'A34'\n",
      " 'C104' 'C111' 'C92' 'E38' 'D21' 'E12' 'E63' 'A14' 'B37' 'C30' 'D20' 'B79'\n",
      " 'E25' 'D46' 'B73' 'C95' 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'C101' 'C68'\n",
      " 'A10' 'E68' 'B41' 'A20' 'D19' 'D50' 'D9' 'A23' 'B50' 'A26' 'D48' 'E58'\n",
      " 'C126' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'F G63' 'C62 C64' 'E24' 'C90'\n",
      " 'C45' 'E8' 'B101' 'D45' 'C46' 'D30' 'E121' 'D11' 'E77' 'F38' 'B3' 'D6'\n",
      " 'B82 B84' 'D17' 'A36' 'B102' 'B69' 'E49' 'C47' 'D28' 'E17' 'A24' 'C50'\n",
      " 'B42' 'C148']\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "len_c_missing = df.Cabin.isna().sum()\n",
    "len_c = len(df.Cabin)\n",
    "print(\"Column 'Cabin' contains {} missing values out of {} total ({}%).\".format(len_c_missing, len_c, round((len_c_missing/len_c)*100, 2)))\n",
    "print(\"Column 'Cabin' contains the following unique values:\\n{}\".format(df.Cabin.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this many missing values, it's probably best for us to just drop this column completely.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* drop the `Cabin` column in place from the `df` DataFrame\n",
    "* Then, check the remaining number of null values in the data set by using the code you wrote previously.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived Pclass  \\\n",
       "0           0            1         0      3   \n",
       "1           1            2         1      1   \n",
       "2           2            3         1      3   \n",
       "3           3            4         1      1   \n",
       "4           4            5         0      3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked  \n",
       "0      0         A/5 21171   7.2500        S  \n",
       "1      0          PC 17599  71.2833        C  \n",
       "2      0  STON/O2. 3101282   7.9250        S  \n",
       "3      0            113803  53.1000        S  \n",
       "4      0            373450   8.0500        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "df.drop('Cabin', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Placeholder Values\n",
    "\n",
    "Recall that another common strategy for dealing with null values is to replace them with the mean or median for that column.  We'll begin by investigating the current version of the `'Age'` column.  \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Plot a histogram of values in the `'Age'` column with 80 bins (1 for each year).   \n",
    "* Print out the mean and median for the column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median age is 28.0, while mean age is 29.7.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "df.Age.plot(kind='hist', figsize=(10,6), bins=80)\n",
    "print(\"Median age is {}, while mean age is {}.\".format(df.Age.median(), round(df.Age.mean(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization above, we can see the data has a slightly positive skew. \n",
    "\n",
    "In the cell below, replace all null values in the `'Age'` column with the median of the column.  **Do not hard code this value--use the methods from pandas or numpy to make this easier!**  Do this replacement in place on the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df.Age.fillna(df.Age.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've replaced the values in the `'Age'` column, let's confirm that they've been replaced.  \n",
    "\n",
    "In the cell below, check how many null values remain in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df.Age.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we need to deal with the two pesky null values in the `'Embarked'` column.  \n",
    "\n",
    "### Dropping Rows That Contain Null Values\n",
    "\n",
    "Perhaps the most common solution to dealing with null values is to simply drop any rows that contain them.  Of course, this is only a good idea if the number dropped does not constitute a significant portion of our dataset.  Often, you'll need to make the overall determination to see if dropping the values is an acceptable loss, or if it is a better idea to just drop an offending column (e.g. the `'Cabin'` column) or to impute placeholder values instead.\n",
    "\n",
    "In the cell below, use the appropriate built-in DataFrame method to drop the rows containing null values. Do this in place on the DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "889\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.dropna(axis=0, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've dealt with all the **_obvious_** null values, but we should also take some time to make sure that there aren't symbols or numbers included that are meant to denote a missing value. \n",
    "\n",
    "### Missing Values with Placeholders\n",
    "\n",
    "A common thing to see when working with datasets is missing values denoted with a preassigned code or symbol.  Let's check to ensure that each categorical column contains only what we expect.\n",
    "\n",
    "In the cell below, return the unique values in the `'Embarked'`, `'Sex'`, `'Pclass'`, and `'Survived'` columns to ensure that there are no values in there that we don't understand or can't account for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Embarked': array(['S', 'C', 'Q'], dtype=object),\n",
       " 'Sex': array(['male', 'female'], dtype=object),\n",
       " 'Pclass': array(['3', '1', '2', '?'], dtype=object),\n",
       " 'Survived': array([0, 1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "cols = ['Embarked', 'Sex', 'Pclass', 'Survived']\n",
    "unique_col_vals = {}\n",
    "for col in cols:\n",
    "    unique_col_vals[col] = df[col].unique()\n",
    "unique_col_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It Looks like the `'Pclass'` column contains some missing values denoted by a placeholder! \n",
    "\n",
    "In the cell below, investigate how many placeholder values this column contains.  Then, deal with these null values using whichever strategy you believe is most appropriate in this case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of rows w/ df.loc[df.Pclass=='?'] is 0.05 (48/889)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "rows_with_Pclass_placeholder = df.loc[df.Pclass == '?']\n",
    "len_rows_with_Pclass_placeholder = len(rows_with_Pclass_placeholder)\n",
    "len_total = len(df)\n",
    "ratio_of_missing_Pclass = len_rows_with_Pclass_placeholder/len_total\n",
    "print(\"Ratio of rows w/ df.loc[df.Pclass=='?'] is {} ({}/{})\".format(round(ratio_of_missing_Pclass, 2), len_rows_with_Pclass_placeholder, len_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since ratio (0.05) of rows w/ df.loc[df.Pclass=='?'] <= .1, dropped 48 offending rows (out of 889 total).\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "#let's adopt the \"rule\" that if the count of offending rows with placeholder data in the given column totals 10% or less of our total dataset then we can just drop those rows\n",
    "#otherwise, drop the column\n",
    "if ratio_of_missing_Pclass > .1: # drop column\n",
    "    df.drop('Pclass', axis=1)\n",
    "    print(\"Since ratio ({}) of rows w/ df.loc[df.Pclass=='?'] > .1, dropped 'Pclass' column.\".format(round(ratio_of_missing_Pclass, 2)))\n",
    "else: # drop rows\n",
    "    df.drop(rows_with_Pclass_placeholder.index, inplace=True)\n",
    "    len_after = len(df)\n",
    "    print(\"Since ratio ({}) of rows w/ df.loc[df.Pclass=='?'] <= .1, dropped {} offending rows (out of {} total).\".format(round(ratio_of_missing_Pclass, 2), (len_total - len_after), len_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** What is the benefit of treating missing values as a separate valid category?  What is the benefit of removing or replacing them? What are the drawbacks of each? Finally, which strategy did you choose? Explain your choice below. \n",
    "\n",
    "Write your answer below this line:\n",
    "The ratio of missing or observations to the total number of observations might give you a sense of confidence of conclusions drawn from any statistics computed on the valid observations: the fewer the missing or invalid observations, the greater the confidence in the statistics computed on the valid observations.  But this assumes that more work will be done to the dataset to exclude invalid observations before computing statstics (in either case).  \n",
    "\n",
    "The benefit of removing or replacing invalid observations is confidence that there will be no errors that occur when the time comes to compute statistics based on valid observations.\n",
    "\n",
    "In my case, I adopted a strategy to dynamically (in code) decide whether to drop the column or set of offending rows based on the number of invalid observations (rows): if the ratio is below 10% of the total number of observations, then,_those rows will be dropped.  Otherwise the column is dropped since otherwise too many rows will be dropped._____________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do a final check to ensure that there are no more null values remaining in this dataset.  \n",
    "\n",
    "In the cell below, reuse the code you wrote at the beginning of the notebook to check how many null values our dataset now contains.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Those all seem in line with our expectations.  We can confidently say that this dataset contains no pesky null values that will mess up our analysis later on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we learned:\n",
    "* How to detect null values in our dataset\n",
    "* How to deal with null values by dropping rows\n",
    "* How to deal with null values by imputing mean/median values \n",
    "* Strategies for detecting null values encoded with a placeholder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
